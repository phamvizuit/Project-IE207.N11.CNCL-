{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeQGPNvCRTFc",
        "outputId": "d3820c62-9817-42ce-be97-491549e60dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Toxic_Spans_Detection'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 150 (delta 72), reused 108 (delta 48), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (150/150), 1.71 MiB | 2.38 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ]
        }
      ],
      "source": [
        "#clone to get dataset\n",
        "!git clone https://github.com/jain-abhinav02/Toxic_Spans_Detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import textblob\n",
        "import json\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "     "
      ],
      "metadata": {
        "id": "-BtHNdlARrW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiEFm3iLSBM4",
        "outputId": "db599b14-3916-4614-82ad-80d20611f351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def f1(preds,trues):\n",
        "    if len(trues) == 0:\n",
        "        return 1. if len(preds) == 0 else 0.\n",
        "    if len(preds) == 0:\n",
        "        return 0.\n",
        "    predictions_set = set(preds)\n",
        "    gold_set = set(trues)\n",
        "    nom = 2 * len(predictions_set.intersection(gold_set))\n",
        "    denom = len(predictions_set) + len(gold_set)\n",
        "    return float(nom)/float(denom)"
      ],
      "metadata": {
        "id": "1fr-NuhiThKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def avg_f1(preds,trues):\n",
        "    avg_f1_total = 0.0\n",
        "    for pred,true in zip(preds,trues):\n",
        "        avg_f1_total += f1(pred,true)\n",
        "    return avg_f1_total/len(preds)\n",
        "     \n"
      ],
      "metadata": {
        "id": "ICzcXfB8Th50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_set = pd.read_csv(\"/content/Toxic_Spans_Detection/datasets/tsd_test.csv\")\n",
        "test_set['spans'] = test_set['spans'].apply(lambda x : json.loads(x))\n",
        "train_set = pd.read_csv(\"/content/Toxic_Spans_Detection/datasets/tsd_train.csv\")\n",
        "train_set['spans'] = train_set['spans'].apply(lambda x : json.loads(x))\n",
        "dataset = test_set.append(train_set,ignore_index=True)\n",
        "dataset['text'] = dataset['text'].apply(lambda x : x.lower())\n",
        "     "
      ],
      "metadata": {
        "id": "u_soMFmcTkY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hate Words list\n",
        "\n",
        "hate_words = pd.read_csv(\"/content/bad-words.csv\")['jigaboo'].to_list()"
      ],
      "metadata": {
        "id": "--xwr8Z6TqmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_all = []\n",
        "for index,row in dataset.iterrows():\n",
        "    text = row['text']\n",
        "    start = 0\n",
        "    indices = []\n",
        "    for word in word_tokenize(text):\n",
        "        word_blob = textblob.TextBlob(word)\n",
        "        if word_blob.polarity < 0:\n",
        "            start_index = text[start:].find(word)\n",
        "            indices += list(range(start + start_index,start + start_index+len(word)))\n",
        "            start += start_index+len(word)\n",
        "    indices_all.append(indices)\n",
        "     \n",
        "\n",
        "toxic_f1 = avg_f1(indices_all,dataset['spans'].to_numpy())\n",
        "     \n",
        "\n",
        "print(\"F1 : %f\"%(toxic_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubToYt-6T-NB",
        "outputId": "bf2db019-0cf1-4894-b7b4-3a157ca900df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 : 0.390830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices_all = []\n",
        "for index,row in dataset.iterrows():\n",
        "    text = row['text']\n",
        "    start = 0\n",
        "    indices = []\n",
        "    for word in word_tokenize(text):\n",
        "        word_blob = textblob.TextBlob(word)\n",
        "        if word_blob.polarity < 0 or word in hate_words:\n",
        "            start_index = text[start:].find(word)\n",
        "            indices += list(range(start + start_index,start + start_index+len(word)))\n",
        "            start += start_index+len(word)\n",
        "    indices_all.append(indices)\n",
        "     \n",
        "\n",
        "toxic_f1 = avg_f1(indices_all,dataset['spans'].to_numpy())\n",
        "     \n",
        "\n",
        "print(\"F1 : %f\"%(toxic_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOUXfQ62T_Bu",
        "outputId": "f2c23fc9-3101-4719-b385-8c7d2c7c4e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 : 0.425147\n"
          ]
        }
      ]
    }
  ]
}